{"meta":{"title":"MyHexo","subtitle":"","description":"","author":"月小白","url":"http://example.com","root":"/"},"pages":[{"title":"个人简历","date":"2023-03-16T13:50:10.234Z","updated":"2023-03-16T13:50:10.234Z","comments":true,"path":"about.html","permalink":"http://example.com/about.html","excerpt":"","text":""},{"title":"文章归档","date":"2023-03-16T13:41:40.283Z","updated":"2023-03-16T13:41:40.283Z","comments":true,"path":"archive.html","permalink":"http://example.com/archive.html","excerpt":"","text":""}],"posts":[{"title":"Score-based diffusion","slug":"NCSN","date":"2023-04-27T08:09:36.730Z","updated":"2023-04-27T08:22:25.101Z","comments":true,"path":"2023/04/27/NCSN/","link":"","permalink":"http://example.com/2023/04/27/NCSN/","excerpt":"","text":"宋飏博士的论文《Score-Based Generative Modeling through Stochastic Differential Equations》是Score-based Diffusion的来源. 起源 能量模型 根据能量模型的理论，任意一个概率分布都可以用一个更通用的形式来表示 pθ(x)=exp⁡(−Eθ(x))Z(θ)p_\\theta(x)=\\dfrac{\\exp(-\\mathbb{E}_\\theta(x))}{Z(\\theta)}pθ​(x)=Z(θ)exp(−Eθ​(x))​ 其中，分母是归一化的配分函数 最直接的优化方法就是求MLE（Maximum Likelihood Expectation），但是由于Z的存在，无法直接优化，但是又可以利用MCMC的方法估计对数似然的梯度，得到 ∇θlog⁡pθ(x)=−∇θEθ(x)−∇θlog⁡(Zθ)\\nabla_\\theta\\log p_\\theta(x)= - \\nabla_\\theta\\mathbb{E}_\\theta(x)-\\nabla_\\theta\\log(Z_\\theta)∇θ​logpθ​(x)=−∇θ​Eθ​(x)−∇θ​log(Zθ​) 第一项可以直接梯度下降，第二项可以展开得到一个无偏的单样本估计： ∇θlog⁡(Zθ)≃−∇θEθ(x~),&nbsp;x~∼pθ(x)\\nabla_\\theta\\log(Z_\\theta)\\simeq- \\nabla_\\theta\\mathbb{E}_\\theta(\\tilde x),\\ \\tilde x \\sim p_\\theta(x)∇θ​log(Zθ​)≃−∇θ​Eθ​(x~),&nbsp;x~∼pθ​(x) 什么是无偏估计呢？就是每个样本的概率都一样。 而这个样本是从能量模型构建的分布中采样出来的，所以只要可以从模型中采样，就可以得到这一项，因此两项都可以求。但是采样这件事本身不是很简单，宋飏博士提到了两种采样方法，Langevin MCMC和Hamiltonian Monte Carlo，都利用了对数似然对样本的梯度就是对能量函数 E\\mathbb{E}E 的负梯度这一事实，即 ∇xlog⁡pθ(x)=−∇xEθ(x)−∇xlog⁡(Zθ)=−∇xEθ(x)\\nabla_x \\log p_\\theta(x)= - \\nabla_x \\mathbb{E}_\\theta(x)-\\nabla_x\\log(Z_\\theta)=- \\nabla_x \\mathbb{E}_\\theta(x)∇x​logpθ​(x)=−∇x​Eθ​(x)−∇x​log(Zθ​)=−∇x​Eθ​(x) 中间式中，由于第二项与x无关，所以梯度为0。 然后根据朗之万动力学采样（Langevin-MCMC） xk+1←xk+ϵ22∇xlog⁡pθ(xk)+ϵzk,k=0,1,...,K−1x^{k+1}\\leftarrow x^k+\\dfrac{\\epsilon^2}{2}\\nabla_x\\log p_\\theta(x^k)+\\epsilon z^k, k=0,1,...,K-1xk+1←xk+2ϵ2​∇x​logpθ​(xk)+ϵzk,k=0,1,...,K−1 当 ϵ\\epsilonϵ 足够小且迭代步数 KKK 足够大的情况下可以近似从 pθp_\\thetapθ​ 中采样 这样我们就可以通过估计 pθp_\\thetapθ​ 对输入 xxx 的梯度（也就是所谓的score）来实现采样，从而使得MLE可求。 总结一下，我们对能量模型参数的每一次随机梯度更新，都需要使用MCMC来近似从分布里采样，来估计梯度的计算。这样做会需要大量样本，从而带来非常大的计算量。 Score Matching 用神经网络来拟合score，就是score matching，优化目标为 DF(p(x)∥pθ(x))=Ep[∣∣∇xlog⁡p(x)−sθ(x))∣∣22]D_F(p(x)\\parallel p_\\theta(x))=\\mathbb{E}_{p}[||\\nabla_x \\log p(x)-s_\\theta(x))||^2_2]DF​(p(x)∥pθ​(x))=Ep​[∣∣∇x​logp(x)−sθ​(x))∣∣22​] Score matching 的目标就是使得真实数据分布对输入x的对数似然的梯度（score）和我们所建模的近似分布的score一致。然后，根据一阶导处处相等，且概率密度函数积分都为1，所以两个数据分布一致。 一个对score比较直观的解释就是“矢量场”，也是宋飏博士在论文中借用的可视化方式。 两个焦点意味着数据分布中心，而位于场的其余位置的数据可以通过梯度下降的方式收敛到数据分布的高概率密度区域。 但是哪怕我们直接将能量模型建模成score，然后根据训练好的能量模型的score来进行MCMC采样，也依然逃不过对分布的计算。但有大量的工作让我们可以直接计算score-matching，而不需要计算真实数据分布。同时这些方法还足够快，只涉及到一阶导数的计算。因此，效率会大大提高。 痛点 利用神经网络近似score function，然后使用朗之万动力学采样目标分布的样本，但是简单地使用上面的score matching方案会有两个问题： 大部分我们希望拟合的数据（比如图像）在高维空间里表现为低维流形。而大部分采样的点不落在低维流形上则其概率为零，对零概率的点取对数（score的定义是logP(x))无意义。 score function的优化目标是个L2范数的期望，而对于低密度的区域该期望因无法得到足够多的样本来监督训练，其准确度也不高。该问题和以上的低维流形问题一起加剧了采样结果的不理想情况。 而根据宋飏博士的论文，以上两个问题都会被往数据里添加高斯噪声所解决。 高斯噪声的定义域是整个参数空间，所以对原数据添加高斯噪声解决了低维流形的零概率问题。 添加大量的高斯噪声实质上扩展了分布里的各个众数的范围，使得数据分布里的低概率区得到了更多监督信号。 但是高斯噪声的尺度选择不是个简单的问题，加过大的噪声虽然会覆盖更多的低概率空间，但同时也会剧烈地改变原数据分布，但过小的噪声又会使得低概率空间的监督信号不足，尽管小噪声可以获得对原数据分布更好的近似。 而作者最终采用的方案是添加一系列不同尺度的噪声，并训练一个条件于噪声大小的score matching网络（noise-conditioned-score-based-model）对他们进行拟合。 原理 使用NCSN学习score function，然后使用 annealed Langevin dynamics 采样 NCSN 定义一组几格级数序列（等比数列）{σi}i=1L\\{\\sigma_i\\}_{i=1}^L{σi​}i=1L​ ，其中 σi&gt;0\\sigma_i&gt;0σi​&gt;0 且 σ1σ2=σ2σ3=⋯=σL−1σL&gt;1\\dfrac{\\sigma_1}{\\sigma_2}=\\dfrac{\\sigma_2}{\\sigma_3}=\\cdots=\\dfrac{\\sigma_{L-1}}{\\sigma_{L}}&gt;1σ2​σ1​​=σ3​σ2​​=⋯=σL​σL−1​​&gt;1 ，用分布 qσ(x)=∫p(x)N(x∣t,σ2I)dtq_\\sigma(x)=\\int p(x)\\mathcal{N}(x|t,\\sigma^2\\mathbf{I})dtqσ​(x)=∫p(x)N(x∣t,σ2I)dt 表示扰动噪声数据分布。 加入噪声扰动后的数据分布为 qσ(x~∣x)=N(x~∣x,σ2I)q_\\sigma(\\tilde x|x)=\\mathcal{N}(\\tilde x|x,\\sigma^2\\mathbf{I})qσ​(x~∣x)=N(x~∣x,σ2I) ，则概率密度函数为 然而 x~=x+σϵ\\tilde x = x + \\sigma\\epsilonx~=x+σϵ ，因此 ∇x~log⁡[qσ(x~∣x)]=−ϵσ\\nabla_{\\tilde x} \\log[q_\\sigma(\\tilde x | x)]=-\\dfrac{\\epsilon}{\\sigma}∇x~​log[qσ​(x~∣x)]=−σϵ​ 这其实是make sense的，因为梯度更新的方向是噪声的反方向，实质上等价于去噪的过程，所以这也是score matching和DDPM的联系，在损失函数上也是一致的。 这里引用[2]的证明： 根据Tweedie’s Formula，对于一个高斯变量 z∼N(z;μz,Σz)z\\sim\\mathcal{N}(z;\\mu_z,\\Sigma_z)z∼N(z;μz​,Σz​) ，有： μz=z+Σz∇zlog⁡p(z)\\mu_z = z + \\Sigma_z\\nabla_z\\log p(z)μz​=z+Σz​∇z​logp(z) 套用到前向过程 xt∼q(xt∣x0)=N(xt;αˉtx0,(1−αˉt)I)x_t\\sim q(x_t|x_0)=\\mathcal{N}(x_t;\\sqrt{\\bar\\alpha_t}x_0,(1-\\bar\\alpha_t)\\mathbf{I})xt​∼q(xt​∣x0​)=N(xt​;αˉt​​x0​,(1−αˉt​)I) 中，得 αˉtx0=xt+(1−αˉt)∇xtlog⁡p(xt)\\sqrt{\\bar\\alpha_t}x_0=x_t+(1-\\bar\\alpha_t)\\nabla_{x_t}\\log p(x_t)αˉt​​x0​=xt​+(1−αˉt​)∇xt​​logp(xt​) 做一下关于 x0x_0x0​ 的等价变化 x0=xt+(1−αˉt)∇xtlog⁡p(xt)αˉt=xt−1−αˉtϵtαˉt→∇xtlog⁡p(xt)=−ϵt1−αˉtx_0=\\dfrac{x_t+(1-\\bar\\alpha_t)\\nabla_{x_t}\\log p(x_t)}{\\sqrt{\\bar\\alpha_t}}=\\dfrac{x_t-\\sqrt{1-\\bar\\alpha_t}\\epsilon_t}{\\sqrt{\\bar\\alpha_t}} \\rightarrow \\nabla_{x_t}\\log p(x_t)=-\\dfrac{\\epsilon_t}{\\sqrt{1-\\bar\\alpha_t}}x0​=αˉt​​xt​+(1−αˉt​)∇xt​​logp(xt​)​=αˉt​​xt​−1−αˉt​​ϵt​​→∇xt​​logp(xt​)=−1−αˉt​​ϵt​​ 代入到DDPM中推导出来的 μq\\mu_qμq​ 中，可以得到 μq=1αtxt+1−αtαt∇xtlog⁡p(xt)\\mu_q=\\dfrac{1}{\\sqrt{\\alpha_t}}x_t+\\dfrac{1-\\alpha_t}{\\sqrt{\\alpha_t}}\\nabla_{x_t}\\log p(x_t)μq​=αt​​1​xt​+αt​​1−αt​​∇xt​​logp(xt​) 类似地，逆向过程可以建模为 μθ=1αtxt+1−αtαtsθ(xt,t)\\mu_\\theta=\\dfrac{1}{\\sqrt{\\alpha_t}}x_t+\\dfrac{1-\\alpha_t}{\\sqrt{\\alpha_t}}s_\\theta(x_t,t)μθ​=αt​​1​xt​+αt​​1−αt​​sθ​(xt​,t) 这样DDPM中的优化目标和score matching的优化目标其实就是一致的了。 但是对于训练目标 l(θ,σ)=Epσ(x)[∣∣x~−xσ2+sθ(x))∣∣22]l(\\theta,\\sigma)=\\mathbb{E}_{p_{\\sigma}(x)}[|| \\dfrac{\\tilde x-x}{\\sigma^2} + s_\\theta(x))||^2_2]l(θ,σ)=Epσ​(x)​[∣∣σ2x~−x​+sθ​(x))∣∣22​] 其关于 σ\\sigmaσ 的量级（噪声级别）是 1σ2\\dfrac{1}{\\sigma^2}σ21​ ，受到 σ\\sigmaσ 的大小的影响，因此如果我们对其加权，权重为 σ2\\sigma^2σ2 ，那最终所有级别的噪声的损失都在同一量级，不再受大小的影响，从而保证了模型的公平性，不会过分重视或者忽视某个噪声级别所要学习的内容。因此最终的训练损失为： L(θ,{σi}i=1L)=1L∑i=1Lλ(σi)l(θ,σi),&nbsp;λ(σi)=σi2L(\\theta,\\{\\sigma_i\\}_{i=1}^L)=\\dfrac{1}{L}\\sum\\limits_{i=1}^{L}\\lambda(\\sigma_i)l(\\theta,\\sigma_i), \\ \\lambda(\\sigma_i)=\\sigma_i^2L(θ,{σi​}i=1L​)=L1​i=1∑L​λ(σi​)l(θ,σi​),&nbsp;λ(σi​)=σi2​ 在这种训练方式下，只要预先设定好 {σi}i=1L\\{\\sigma_i\\}_{i=1}^L{σi​}i=1L​ ，然后在每次迭代时随机选取其中一个噪声级别 σi\\sigma_iσi​ ，并采样一个标准高斯噪声 ϵ\\epsilonϵ ，对原始数据样本加噪：x~=x+σiϵ\\tilde x=x+\\sigma_i\\epsilonx~=x+σi​ϵ ，接着将加噪后的样本 x~\\tilde xx~ 与对应的噪声级别 σi\\sigma_iσi​ 一并丢给网络得到预测的分数 sθ(x~,σi)s_\\theta(\\tilde x,\\sigma_i)sθ​(x~,σi​) ，然后就可以使用上述损失函数来计算损失了。 具体算法流程如下： 1234567891011121314151617181920def anneal_dsm_score_estimation(scorenet, samples, labels, sigmas, anneal_power=2.): # 取出每个样本对应噪声级别下的噪声分布的标准差，即公式中的sigma_i， # 这里的 labels 是用于标识每个样本的噪声级别的，就是 i，实际是一种索引标识 # (bs,)-&gt;(bs,1,1,1) 扩展至与图像一致的维度数 used_sigmas = sigmas[labels].view(samples.shape[0], *([1] * len(samples.shape[1:]))) # 加噪：x' = x + sigma * z (z ~ N(0,1)) perturbed_samples = samples + torch.randn_like(samples) * used_sigmas # 目标score，本质是对数条件概率密度 log(p(x'|x)) 对噪声数据 x' 的梯度 # 由于这里建模为高斯分布，因此可计算出结果最终如下 target = - 1 / (used_sigmas ** 2) * (perturbed_samples - samples) # 模型预测的 score scores = scorenet(perturbed_samples, labels) target = target.view(target.shape[0], -1) scores = scores.view(scores.shape[0], -1) # 先计算每个样本在所有维度下分数估计的误差总和，再对所有样本求平均 loss = 1 / 2. * ((scores - target) ** 2).sum(dim=-1) * used_sigmas.squeeze() ** anneal_power return loss.mean(dim=0) Annealed Langevin Dynamics 代码如下： 12345678910111213141516171819202122232425def anneal_Langevin_dynamics(self, x_mod, scorenet, sigmas, n_steps_each=100, step_lr=0.00002): images = [] with torch.no_grad(): # 依次在每个噪声级别下进行朗之万动力学采样生成，噪声强度递减 for c, sigma in tqdm.tqdm(enumerate(sigmas), total=len(sigmas), desc='annealed Langevin dynamics sampling'): # 噪声级别 labels = torch.ones(x_mod.shape[0], device=x_mod.device) * c labels = labels.long() # 这个步长并非 Algorithm 1 中的 alpha，而是其中第6步的 alpha/2 # 对应朗之万动力学采样公式(见公式(vi))的 epsilon/2 step_size = step_lr * (sigma / sigmas[-1]) ** 2 # 每个噪声级别下进行一定步数的朗之万动力学采样生成 for s in range(n_steps_each): images.append(torch.clamp(x_mod, 0.0, 1.0).to('cpu')) # 对应朗之万公式最后一项 noise = torch.randn_like(x_mod) * np.sqrt(step_size * 2) # 网络估计的分数 grad = scorenet(x_mod, labels) # 朗之万动力方程 x_mod = x_mod + step_size * grad + noise return images 参考文献： [1] 一文解释 经验贝叶斯估计, Tweedie’s formula - 知乎 (zhihu.com) [2] 一文解释 Diffusion Model (二) Score-based SDE 理论推导 - 知乎 (zhihu.com) [3] Generative Modeling by Estimating Gradients of the Data Distribution | Yang Song (yang-song.net) [4] Score Matching 系列 (一) Non-normalized 模型估計 | 棒棒生 (bobondemon.github.io) [5] 基于分数的生成模型（Score-based Generative Model ） - 知乎 (zhihu.com) [6] 生成扩散模型漫谈（五）：一般框架之SDE篇 - 科学空间|Scientific Spaces [7] 扩散模型与能量模型，Score-Matching和SDE，ODE的关系 - 知乎 (zhihu.com) [8] 浅谈扩散模型的有分类器引导和无分类器引导 - 知乎 (zhihu.com) [9] How to Train Your Energy-Based Models [10] 图像生成别只知道扩散模型(Diffusion Models)，还有基于梯度去噪的分数模型：NCSN(Noise Conditional Score Networks) - 知乎 (zhihu.com)","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"score-based","slug":"score-based","permalink":"http://example.com/tags/score-based/"},{"name":"energy model","slug":"energy-model","permalink":"http://example.com/tags/energy-model/"},{"name":"diffusion","slug":"diffusion","permalink":"http://example.com/tags/diffusion/"},{"name":"generative","slug":"generative","permalink":"http://example.com/tags/generative/"}]},{"title":"Denoising Diffusion Probabilistic Model","slug":"DDPM","date":"2023-04-26T06:51:38.339Z","updated":"2023-04-27T08:22:19.521Z","comments":true,"path":"2023/04/26/DDPM/","link":"","permalink":"http://example.com/2023/04/26/DDPM/","excerpt":"","text":"直观 从直观的视角看，引用苏剑林大佬的描述[1]，DDPM所做的就是将高楼大厦拆成原材料，然后从原材料再重建成高楼大厦。让模型学习拆楼的过程，知道某一时刻的状态是初始大楼经过一定步之后怎么拆出来的，这样模型就能知道每一步大概是怎么拆的，反过来也能知道该怎么建回去。 看意思很简单，难点在于，拆大楼的时候可能是这里拆一块砖，那里拆一块砖，随机性很强，并非是确定的过程，所以逆向重建几乎成了不可能的事。 因此，需要将问题建模，利用数学工具求解这一问题。 原理 借鉴Lil大佬的分享[2]，我也来试图拆解一下Diffusion Model 首先定义一下问题，设 xi∼q(xi),i=0,1,...,Tx_i \\sim q(x_i), i=0,1,...,Txi​∼q(xi​),i=0,1,...,T ，其中 x0x_0x0​ 是初始状态，通过前向扩散过程得到 x1,x2,...,xTx_1, x_2, ... , x_Tx1​,x2​,...,xT​，已知扩散过程为 xt=atxt−1+btϵt,&nbsp;ϵt∼N(0,I)x_t = a_t x_{t-1}+b_t \\epsilon_{t},\\ \\epsilon_t \\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I})xt​=at​xt−1​+bt​ϵt​,&nbsp;ϵt​∼N(0,I) 其中 ϵt\\epsilon_tϵt​ 代表t时刻加入的噪声。展开后可以得到： 除第一项以外，后面是多个独立同分布的正态噪声之和，利用 z∼N(0,I),&nbsp;(Az+Bz+C)∼N(C,A2+B2I)z\\sim\\mathcal{N}(0,I), \\ (Az+Bz+C)\\sim\\mathcal{N}(C, \\sqrt{A^2+B^2}\\mathbf{I})z∼N(0,I),&nbsp;(Az+Bz+C)∼N(C,A2+B2​I) 上式可改写为 xt=(at⋯a1)x0+(at⋯a2)2b12+⋯+at2bt−12+bt2ϵˉt,&nbsp;ϵˉt∼N(0,I)x_t=(a_t\\cdots a_1)x_0 +\\sqrt{(a_t\\cdots a_2)^2b_1^2+\\cdots+a_t^2b_{t-1}^2+b_t^2}\\bar\\epsilon_t,\\ \\bar\\epsilon_t\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})xt​=(at​⋯a1​)x0​+(at​⋯a2​)2b12​+⋯+at2​bt−12​+bt2​​ϵˉt​,&nbsp;ϵˉt​∼N(0,I) 而这其实也是一个正态分布，而且如果我们将系数的平方加起来的话可以得到： 如果令 ai2+bi2=1a_i^2+b_i^2=1ai2​+bi2​=1 的话，就可以简化上面的平方和为1，因此所有的表达式都可以被简化 这就是原论文中设定 xt=1−βtxt−1+βtϵtx_t = \\sqrt{1-\\beta_t}x_{t-1}+\\sqrt{\\beta_t}\\epsilon_txt​=1−βt​​xt−1​+βt​​ϵt​ 的原因 为了与原论文统一起来，下面也用原论文的设定。 令 αt=1−βt,&nbsp;αˉt=∏itαi\\alpha_t = 1-\\beta_t,\\ \\bar\\alpha_t=\\prod_i^t{\\alpha_i}αt​=1−βt​,&nbsp;αˉt​=∏it​αi​ ，则 xt=αtxt−1+1−αtϵt=αˉtx0+1−αˉtϵˉtx_t=\\sqrt{\\alpha_t}x_{t-1}+\\sqrt{1-\\alpha_t}\\epsilon_t=\\sqrt{\\bar\\alpha_t}x_0+\\sqrt{1-\\bar\\alpha_t}\\bar\\epsilon_txt​=αt​​xt−1​+1−αt​​ϵt​=αˉt​​x0​+1−αˉt​​ϵˉt​ 上述过程也可以看作从一个高斯分布中采样，即 整个前向过程是一个后验估计，可以表示为： q(x1:T∣x0)=∏t=1Tq(xt∣xt−1)q(x_{1:T}|x_0)=\\prod_{t=1}^T{q(x_t|x_{t-1})}q(x1:T​∣x0​)=∏t=1T​q(xt​∣xt−1​) 逆向过程就是将原材料再组合成初始的大楼，我们没办法一下子做到，但是如果知道每一步应该怎么做，那给足时间，我们就能充分还原。 所以建模每一步逆向过程为 pθ(xt−1∣xt)p_\\theta(x_{t-1}|x_t)pθ​(xt−1​∣xt​), 由于扩散的每一步我们都建模成高斯分布，那不妨逆向也设成高斯分布（事实上，文献《On the theory of stochastic processes, with particular reference to applications》证明了如果 q(xt∣xt−1)q(x_t|x_{t-1})q(xt​∣xt−1​) 满足高斯分布且 βt\\beta_tβt​ 足够小的话，q(xt−1∣xt)q(x_{t-1}|x_t)q(xt−1​∣xt​) 仍然是一个高斯分布），只不过前面的参数是确定的，而后面的参数不确定。我们先记作 pθ(xt−1∣xt)=N(xt−1;μθ(xt,t),Σθ(xt,t))p_\\theta(x_{t-1}|x_t)=\\mathcal{N}(x_t-1;\\mu_\\theta(x_t,t),\\Sigma_\\theta(x_t, t))pθ​(xt−1​∣xt​)=N(xt​−1;μθ​(xt​,t),Σθ​(xt​,t)) ，整个逆向过程则可以表示成一个联合概率分布 pθ(x0:T)=p(xT)∏t=1Tpθ(xt−1∣xt)p_\\theta(x_{0:T})=p(x_T)\\prod_{t=1}^T{p_\\theta(x_{t-1}|x_t)}pθ​(x0:T​)=p(xT​)∏t=1T​pθ​(xt−1​∣xt​) 值得注意的是，我们无法直接估计 q(xt−1∣xt)q(x_{t-1}|x_t)q(xt−1​∣xt​) ，因为这是个先验概率，需要用到整个数据集，但是在知道初始状态 x0x_0x0​ 的情况下，我们可以计算这个条件概率： 根据 z∝exp⁡(−12(x−μ)2σ2),&nbsp;z∼N(0,I)z \\varpropto \\exp(-\\dfrac{1}{2}\\dfrac{(x-\\mu)^2}{\\sigma^2}),\\ z \\sim \\mathcal{N}(\\mathbf{0},\\mathbf{I})z∝exp(−21​σ2(x−μ)2​),&nbsp;z∼N(0,I) ，假设 q(xt−1∣xt,x0)=N(xt−1;μ~(xt,x0),β~tI)q(x_{t-1}|x_t,x_0)=\\mathcal{N}(x_{t-1};\\tilde\\mu(x_t,x_0),\\tilde\\beta_t\\mathbf{I})q(xt−1​∣xt​,x0​)=N(xt−1​;μ~​(xt​,x0​),β~​t​I) ，则可以求得 现在，我们知道给定前向过程的时候怎么求逆向了，那我们的目标就是使 pθ(x0)p_\\theta(x_0)pθ​(x0​) 尽可能和 q(x0)q(x_0)q(x0​) 一致，自然想到了交叉熵 L=Eq(x0)[−log⁡pθ(x0)]\\mathcal{L} = \\mathbb{E}_{q(x_0)}[-\\log{p_\\theta(x_0)}]L=Eq(x0​)​[−logpθ​(x0​)] =−Eq(x0)[log⁡(pθ(x0)⋅∫pθ(x1:T)dx1:T)]=-\\mathbb{E}_{q(x_0)}[\\log({p_\\theta(x_0)} \\cdot \\int{p_\\theta(x_{1:T})dx_{1:T}})]=−Eq(x0​)​[log(pθ​(x0​)⋅∫pθ​(x1:T​)dx1:T​)] =−Eq(x0)[log⁡(∫pθ(x0:T)dx1:T)]=-\\mathbb{E}_{q(x_0)}[\\log(\\int{p_\\theta(x_{0:T})dx_{1:T}})]=−Eq(x0​)​[log(∫pθ​(x0:T​)dx1:T​)] =−Eq(x0)[log⁡(∫q(x1:T∣x0)pθ(x0:T)q(x1:T∣x0)dx1:T)]=-\\mathbb{E}_{q(x_0)}[\\log(\\int{q(x_{1:T}|x_0)\\dfrac{p_\\theta(x_{0:T})}{q(x_{1:T}|x_0)}dx_{1:T}})]=−Eq(x0​)​[log(∫q(x1:T​∣x0​)q(x1:T​∣x0​)pθ​(x0:T​)​dx1:T​)] =−Eq(x0)log⁡(Eq(x1:T∣x0)pθ(x0:T)q(x1:T∣x0))=-\\mathbb{E}_{q(x_0)}\\log(\\mathbb{E}_{q(x_{1:T}|x_0)}{\\dfrac{p_\\theta(x_{0:T})}{q(x_{1:T}|x_0)}})=−Eq(x0​)​log(Eq(x1:T​∣x0​)​q(x1:T​∣x0​)pθ​(x0:T​)​) ≤−Eq(x0:T∣x0)[log⁡pθ(x0:T)q(x1:T∣x0)]\\le-\\mathbb{E}_{q(x_{0:T}|x_0)}[\\log{\\dfrac{p_\\theta(x_{0:T})}{q(x_{1:T}|x_0)}}]≤−Eq(x0:T​∣x0​)​[logq(x1:T​∣x0​)pθ​(x0:T​)​] =Eq(x0:T∣x0)[log⁡q(x1:T∣x0)pθ(x0:T)]=\\mathbb{E}_{q(x_{0:T}|x_0)}[\\log{\\dfrac{q(x_{1:T}|x_0)}{p_\\theta(x_{0:T})}}]=Eq(x0:T​∣x0​)​[logpθ​(x0:T​)q(x1:T​∣x0​)​] =VLB=VLB=VLB =Eq[log⁡∏t=1Tq(xt∣xt−1)pθ(xT)∏t=1Tpθ(xt−1∣xt)]=\\mathbb{E}_q[\\log{\\dfrac{\\prod_{t=1}^{T}q(x_t|x_{t-1})}{p_\\theta(x_T)\\prod_{t=1}^{T}p_\\theta(x_{t-1}|x_t)}}]=Eq​[logpθ​(xT​)∏t=1T​pθ​(xt−1​∣xt​)∏t=1T​q(xt​∣xt−1​)​] =Eq[−log⁡pθ(xT)+∑t=1Tlog⁡q(xt∣xt−1)pθ(xt−1∣xt)]=\\mathbb{E}_q[-\\log{p_\\theta(x_T)}+\\sum\\limits_{t=1}^T{\\log{\\dfrac{q(x_t|x_{t-1})}{p_\\theta(x_{t-1}|x_t)}}}]=Eq​[−logpθ​(xT​)+t=1∑T​logpθ​(xt−1​∣xt​)q(xt​∣xt−1​)​] =Eq[−log⁡pθ(xT)+∑t=2Tlog⁡(q(xt−1∣xt,x0)pθ(xt−1∣xt)⋅q(xt∣x0)pθ(xt−1∣x0))+log⁡q(x1∣x0)pθ(x0∣x1)]=\\mathbb{E}_q[-\\log{p_\\theta(x_T)}+\\sum\\limits_{t=2}^T{\\log{(\\dfrac{q(x_{t-1}|x_t, x_0)}{p_\\theta(x_{t-1}|x_t)}\\cdot\\dfrac{q(x_t|x_0)}{p_\\theta(x_{t-1}|x_0)})+\\log\\dfrac{q(x_1|x_0)}{p_\\theta(x_0|x_1)}}}]=Eq​[−logpθ​(xT​)+t=2∑T​log(pθ​(xt−1​∣xt​)q(xt−1​∣xt​,x0​)​⋅pθ​(xt−1​∣x0​)q(xt​∣x0​)​)+logpθ​(x0​∣x1​)q(x1​∣x0​)​] =Eq[log⁡q(xT∣x0)pθ(xT)+∑t=2Tlog⁡q(xt−1∣xt,x0)pθ(xt−1∣xt)−log⁡pθ(x0∣x1)]=\\mathbb{E}_q[\\log\\dfrac{q(x_T|x_0)}{p_\\theta(x_T)}+\\sum\\limits_{t=2}^T{\\log\\dfrac{q(x_{t-1}|x_t,x_0)}{p_\\theta(x_{t-1}|x_t)} - \\log p_\\theta(x_0|x_1)}]=Eq​[logpθ​(xT​)q(xT​∣x0​)​+t=2∑T​logpθ​(xt−1​∣xt​)q(xt−1​∣xt​,x0​)​−logpθ​(x0​∣x1​)] =Eq[DKL(q(xT∣x0)∥pθ(xT))+∑t=2TDKL(q(xt−1∣xt,x0)∥pθ(xt−1∣xt))−log⁡pθ(x0∣x1)]=\\mathbb{E}_q[D_{KL}(q(x_T|x_0)\\parallel p_\\theta(x_T))+\\sum\\limits_{t=2}^T{D_{KL}(q(x_{t-1}|x_t,x_0)\\parallel p_\\theta(x_{t-1}|x_t))}-\\log p_\\theta(x_0|x_1)]=Eq​[DKL​(q(xT​∣x0​)∥pθ​(xT​))+t=2∑T​DKL​(q(xt−1​∣xt​,x0​)∥pθ​(xt−1​∣xt​))−logpθ​(x0​∣x1​)] 第一步，交叉熵定义；第二步，边际概率之和为1；第三步，合并；第四步，凑；第五步，期望的定义；第六步，Jensen不等式；第七、八步，改写；第九步，带入定义；第十步，log运算；第十一步，前向转换成逆向；第十二步，约分；第十三步，KL散度定义 最后得到三项，第一项是常数，两个分布都是已知量，第二项是两个高斯分布的KL散度，第三项是重建系数，DDPM专门为此构建了一个离散化的分段积分累乘，在此不需要特别关注。 其实可以看出，第二项就是希望重建的每一步和逆扩散的每一步尽可能相似 第二项的解为 Lt=Ex0,ϵ[12∥Σθ∥22∥μ~t(xt,x0)−μθ(xt,t)∥2]\\mathcal{L}_t=\\mathbb{E}_{x_0,\\epsilon}[\\dfrac{1}{2\\Vert\\Sigma_\\theta \\Vert^2_2}\\Vert \\tilde\\mu_t(x_t, x_0) - \\mu_\\theta(x_t,t) \\Vert^2]Lt​=Ex0​,ϵ​[2∥Σθ​∥22​1​∥μ~​t​(xt​,x0​)−μθ​(xt​,t)∥2] =Ex0,ϵ[Ct∥ϵt−ϵθ(αˉtx0+1−αˉtϵˉt,t)∥2]=\\mathbb{E}_{x_0,\\epsilon}[C_{t}\\Vert \\epsilon_t - \\epsilon_\\theta(\\sqrt{\\bar\\alpha_t}x_0+\\sqrt{1-\\bar\\alpha_t}\\bar\\epsilon_t,t) \\Vert^2]=Ex0​,ϵ​[Ct​∥ϵt​−ϵθ​(αˉt​​x0​+1−αˉt​​ϵˉt​,t)∥2] 所以，模型最后学习的其实就是给定t时刻后的噪声，因此，有了以下的算法流程 细节点 为什么已经知道了前向过程，不能用 xtx_txt​ 直接求 x0x_0x0​ 呢 ​ 第一，这样做并没有意义，第二，仅仅通过公式求 x0x_0x0​ 需要记住所有的随机噪声，如果仅利用最后的表达式，噪声的权重相当大，无法恢复原图 重参数的作用 ​ 一个符合高斯分布的随机变量，是无法直接求导的，但是如果将它分解成 z=μθ+σθϵ,&nbsp;ϵ∼N(0,I)z=\\mu_\\theta+\\sigma_\\theta\\epsilon,\\ \\epsilon\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})z=μθ​+σθ​ϵ,&nbsp;ϵ∼N(0,I) 的形式，就可以求导了 VLB是什么 ​ 对于 pθ(x0)p_\\theta(x_0)pθ​(x0​) ，我们求解他的极大似然估计来最大化逆向回 x0x_0x0​ 的概率，这个问题等价于求极小负对数似然，即 ​ ​ Variational Lower Bound，变分下界，我们自然希望它越小越好，这与上面是一致的 为什么 p(xt−1∣xt)p(x_{t-1}|x_t)p(xt−1​∣xt​) 不能直接求 ​ 因为这是个先验，需要遍历所有数据才能求到这个概率分布。举个直白的例子，我知道你30岁的样子，我想知道你20岁长啥样，我没法直接看出来，但是如果我知道了所有人30岁到20岁的变化，我就可以总结出规律，然后推导你20岁的样子，这个规律就是这里的先验。DDPM说，我不需要知道所有人的规律，我只要知道你10岁长啥样我就可以大概推测你20岁长啥样。 明明是求 x0x_0x0​ ，为什么又用 xtx_txt​ 和 x0x_0x0​ 的关系去代入 q(xt−1∣xt,x0)q(x_{t-1}|x_t,x_0)q(xt−1​∣xt​,x0​) 的计算 ​ 这里其实是一个大致的估计，因为这里的 x0x_0x0​ 并不一定是我们最终要求的那个，我们真正要求的可能是更前面或者更后面的结果。因为每一步我们都将重新估计，所以这个 x0x_0x0​ 其实是会被不断修正的，而且随着权重的逐渐降低，最终的预测会更加精细。 参考文献 [1] 生成扩散模型漫谈（一）：DDPM = 拆楼 + 建楼 - 科学空间|Scientific Spaces [2] [What are Diffusion Models? | Lil’Log (lilianweng.github.io)](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#:~:text=Diffusion models are inspired by,data samples from the noise) [3] 扩散模型 Diffusion Models - 原理篇 - 知乎 (zhihu.com) [4] 一文解释 Diffusion Model (一) DDPM 理论推导 - 知乎 (zhihu.com) [5] 由浅入深了解Diffusion Model - 知乎 (zhihu.com)","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"diffusion","slug":"diffusion","permalink":"http://example.com/tags/diffusion/"},{"name":"generative","slug":"generative","permalink":"http://example.com/tags/generative/"},{"name":"DDPM","slug":"DDPM","permalink":"http://example.com/tags/DDPM/"}]},{"title":"【10】八方旅人2","slug":"octopath_traveler2","date":"2023-03-30T03:04:53.945Z","updated":"2023-04-03T12:15:01.745Z","comments":true,"path":"2023/03/30/octopath_traveler2/","link":"","permalink":"http://example.com/2023/03/30/octopath_traveler2/","excerpt":"","text":"个人评分 总体：10 音乐：10 美术：","categories":[{"name":"游戏","slug":"游戏","permalink":"http://example.com/categories/%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Nintendo Switch","slug":"Nintendo-Switch","permalink":"http://example.com/tags/Nintendo-Switch/"},{"name":"Square Enix","slug":"Square-Enix","permalink":"http://example.com/tags/Square-Enix/"}]},{"title":"孔乙己","slug":"kongyiji","date":"2023-03-30T00:35:22.851Z","updated":"2023-03-30T03:11:06.949Z","comments":true,"path":"2023/03/30/kongyiji/","link":"","permalink":"http://example.com/2023/03/30/kongyiji/","excerpt":"","text":"事件 前段时间，有网友自嘲“学历不但是敲门砖，也是我下不来的高台，更是孔乙己脱不下的长衫”，引起广大正当毕业季学生的强烈共鸣。热点一再发酵，央媒纷纷下场，共青团中央推文充满傲慢，直言大学生要脱下“思想上的长衫”，弯弯绕绕地表达，找达不到工作就是个人不努力的结果，不肯“挽起裤腿下田地”的结果。浙江宣传推文相对柔和，但也不过是屁股决定脑袋的文章。央视就更赤裸裸了，“孔乙己之所以陷入生活的困境，不是因为读过书，而是因为放不下读书人的架子，不愿意靠劳动改变自身的处境”。 感想 这下好了，自嘲之语成了党媒攻讦年轻人的武器，好比你自嘲我过的猪狗不如，然后党媒纷纷围上来说，你过的猪狗不如是因为你不够努力。 第一，孔乙己的长衫是自嘲，是用来形容自己的学历情结。但是当代大学生的这件长衫绝对不是酸臭的、迂腐的、破旧不堪的，它可能是一个家庭二三十年的努力，为了能创造更好的生活进行的长远投资。一句脱下长衫，无异于让这些家庭放弃稳定的、可靠的未来，有多少人能接受？ 第二，孔乙己的长衫绝非个人决定的，是当时的时代背景决定的，吃人的封建礼教、冷眼旁观的看客、动荡的政治环境，都促成了哪怕脱下了长衫，也难以活得好的悲惨境遇。像祥子一样拼了命地拉面包车，换来的不过是到死都攒不够钱。央媒只管批判你个人不努力，可曾想过当下的就业环境极其恶劣，没有那么多岗位能容下如此多的大学生。学历膨胀带来的后果就是层层挤压，985本硕的大学生都不好找工作，或者只找得到比之前差多了的工作，那那些211的、普本的呢？当前就业季的大学生恐怕大部分人求职过的公司比他这辈子听说过的公司都多，央媒却说这些年轻人还不够努力，还放不下面子。确实不够努力，但不够努力的或许是他们的爹妈、爷奶吧，没有在当年的打土豪分田地中，努力努力多干两个地主下来，努力努力多分到些蛋糕。 第三，此次毕业季是社会给这一批大学生的一堂课，教会他们阶级是难以逾越的。多少公司，特别是央国企，放出来的岗位上岸者的学历背景与竞争者相差甚远，或者笔试、面试不透明？其实很多都是萝卜坑，供给内部消化。哪怕你生的是条虫，也能让你的孩子去做龙的工作。 第四，北京的报刊、媒体越来越脱离群众，成了真正的政治工具，粉饰太平。 杂谈 此次事件引起了一波又一波的讨论，有支持党媒的，有批判党媒的，也有各打一棒的。只能说，何不食肉糜的人永远都存在。他们没见过、没体会过，所以可以高高在上，指点江山。 北京四中学生对舞会的回应清晰地展现了既得利益者对教育的把控。他们接受的教育中，贫穷只不过是书面的词汇，善良只不过是对同类人的共情，所以他们培养出的学生充分继承了他们的意志，充满优越感。 所以不要期待上层阶级对下能体会，做不到的，他们下不来。","categories":[{"name":"生活随记,社会","slug":"生活随记-社会","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0-%E7%A4%BE%E4%BC%9A/"}],"tags":[{"name":"热点","slug":"热点","permalink":"http://example.com/tags/%E7%83%AD%E7%82%B9/"},{"name":"媒体","slug":"媒体","permalink":"http://example.com/tags/%E5%AA%92%E4%BD%93/"},{"name":"政治","slug":"政治","permalink":"http://example.com/tags/%E6%94%BF%E6%B2%BB/"}]},{"title":"愿望单（持续更新）","slug":"gifts","date":"2023-03-23T06:21:23.755Z","updated":"2023-03-30T00:37:31.468Z","comments":true,"path":"2023/03/23/gifts/","link":"","permalink":"http://example.com/2023/03/23/gifts/","excerpt":"","text":"类别 名称 一般价格 优先度 游戏卡带 炼金工坊 不可思议之炼金术师三部曲 &lt;600 2 宝可梦 阿尔宙斯 &lt;300 3 宝可梦 朱/紫 280 3 异度神剑1：终极版 200 2 异度神剑2 &lt;400 3 运动类 神速90K一代 4u5 &lt;1150 4 神速90K二代 4u5 &lt;1000 3 TK隼黑金 4u5 CN &lt;1100 4 龙牙之刃一代 4u5 &lt;1100 3 生活类 羽亲多功能披肩 300 3 电子类 kindle 1 GPW2代（鼠标） 600 2 乐歌办公升降台 500 2 七彩虹 RTX3070 Ultra OC 3900、2600 4 七彩虹 RTX3060Ti Ultra OC 3500、2400 4 大疆mini2se 2400 2 大疆action3 300 2","categories":[{"name":"生活随记,我","slug":"生活随记-我","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0-%E6%88%91/"}],"tags":[{"name":"礼物","slug":"礼物","permalink":"http://example.com/tags/%E7%A4%BC%E7%89%A9/"}]}],"categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://example.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"游戏","slug":"游戏","permalink":"http://example.com/categories/%E6%B8%B8%E6%88%8F/"},{"name":"生活随记,社会","slug":"生活随记-社会","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0-%E7%A4%BE%E4%BC%9A/"},{"name":"生活随记,我","slug":"生活随记-我","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0-%E6%88%91/"}],"tags":[{"name":"score-based","slug":"score-based","permalink":"http://example.com/tags/score-based/"},{"name":"energy model","slug":"energy-model","permalink":"http://example.com/tags/energy-model/"},{"name":"diffusion","slug":"diffusion","permalink":"http://example.com/tags/diffusion/"},{"name":"generative","slug":"generative","permalink":"http://example.com/tags/generative/"},{"name":"DDPM","slug":"DDPM","permalink":"http://example.com/tags/DDPM/"},{"name":"Nintendo Switch","slug":"Nintendo-Switch","permalink":"http://example.com/tags/Nintendo-Switch/"},{"name":"Square Enix","slug":"Square-Enix","permalink":"http://example.com/tags/Square-Enix/"},{"name":"热点","slug":"热点","permalink":"http://example.com/tags/%E7%83%AD%E7%82%B9/"},{"name":"媒体","slug":"媒体","permalink":"http://example.com/tags/%E5%AA%92%E4%BD%93/"},{"name":"政治","slug":"政治","permalink":"http://example.com/tags/%E6%94%BF%E6%B2%BB/"},{"name":"礼物","slug":"礼物","permalink":"http://example.com/tags/%E7%A4%BC%E7%89%A9/"}]}